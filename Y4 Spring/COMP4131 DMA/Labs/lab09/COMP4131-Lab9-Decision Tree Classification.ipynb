{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac8b444-a7be-4bf9-bcb8-61a0f733fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d7fea-09c8-481d-9b12-657b3bdc6c51",
   "metadata": {},
   "source": [
    "### Step 1: Import Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b7616b-a35e-4fd2-b86a-0a082e8f63d2",
   "metadata": {},
   "source": [
    "The \"real_estate_valuation_data_set.csv\" file saves the market historical data of real estate valuation of a Chinese city. The variable information is as follows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faca92d-be26-4b5d-9f1b-4b5a61fca489",
   "metadata": {},
   "source": [
    "| Variable Name | Role | Type | Description | Units | \n",
    "|:--|:--|:--|:--|:--|\n",
    "|No|ID|Integer||||\n",
    "|X1 transaction date|Feature|Continuous|for example, 2013.250=2013 March, <br>2013.500=2013 June, etc.||\n",
    "|X2 house age|Feature|Continuous||year|\n",
    "|X3 distance to the <br>nearest metro station|Feature|Continuous||meter|\n",
    "|X4 number of <br>convenience stores|Feature|Integer|number of convenience stores in the<br> living circle on foot|integer|\n",
    "|X5 latitude|Feature|Continuous|geographic coordinate, latitude|degree|\n",
    "|X6 longitude|Feature|Continuous|geographic coordinate, longitude|degree|\n",
    "|Y house price of<br> unit area|Target|Continuous|10000 Chinese Yuan per <br>square metre|10000 CNY/<br>square metre|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbc14c25-9804-497d-92f3-b451cdf9650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data with pandas\n",
    "real_estate = pd.read_csv(\"real_estate_valuation_data_set.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e39804f-4e25-4676-87b9-f423976923a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1 transaction date</th>\n",
       "      <th>X2 house age</th>\n",
       "      <th>X3 distance to the nearest MRT station</th>\n",
       "      <th>X4 number of convenience stores</th>\n",
       "      <th>X5 latitude</th>\n",
       "      <th>X6 longitude</th>\n",
       "      <th>Y house price of unit area</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012.917</td>\n",
       "      <td>32.0</td>\n",
       "      <td>84.87882</td>\n",
       "      <td>10</td>\n",
       "      <td>24.98298</td>\n",
       "      <td>121.54024</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012.917</td>\n",
       "      <td>19.5</td>\n",
       "      <td>306.59470</td>\n",
       "      <td>9</td>\n",
       "      <td>24.98034</td>\n",
       "      <td>121.53951</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013.583</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013.500</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012.833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>390.56840</td>\n",
       "      <td>5</td>\n",
       "      <td>24.97937</td>\n",
       "      <td>121.54245</td>\n",
       "      <td>2.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1 transaction date  X2 house age  X3 distance to the nearest MRT station  \\\n",
       "No                                                                              \n",
       "1              2012.917          32.0                                84.87882   \n",
       "2              2012.917          19.5                               306.59470   \n",
       "3              2013.583          13.3                               561.98450   \n",
       "4              2013.500          13.3                               561.98450   \n",
       "5              2012.833           5.0                               390.56840   \n",
       "\n",
       "    X4 number of convenience stores  X5 latitude  X6 longitude  \\\n",
       "No                                                               \n",
       "1                                10     24.98298     121.54024   \n",
       "2                                 9     24.98034     121.53951   \n",
       "3                                 5     24.98746     121.54391   \n",
       "4                                 5     24.98746     121.54391   \n",
       "5                                 5     24.97937     121.54245   \n",
       "\n",
       "    Y house price of unit area  \n",
       "No                              \n",
       "1                         2.53  \n",
       "2                         2.81  \n",
       "3                         3.15  \n",
       "4                         3.65  \n",
       "5                         2.87  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first five rows of the data\n",
    "real_estate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d85f961-6613-4c04-b622-a229fa347a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of instances and features\n",
    "row_num = real_estate.shape[0]\n",
    "col_num = real_estate.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b621ed39-118f-4d50-a50e-14e67248d3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_num, col_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ddb3f9-3532-4108-9551-0925a8dd88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input variables X with features from X1 to X6.\n",
    "X = np.array(real_estate.iloc[:,:6].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2eca421-069a-488b-a316-6677159a5dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff547da2-3373-49bc-93f2-a775f99d45d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2012.917  ,   32.     ,   84.87882,   10.     ,   24.98298,\n",
       "         121.54024],\n",
       "       [2012.917  ,   19.5    ,  306.5947 ,    9.     ,   24.98034,\n",
       "         121.53951],\n",
       "       [2013.583  ,   13.3    ,  561.9845 ,    5.     ,   24.98746,\n",
       "         121.54391],\n",
       "       ...,\n",
       "       [2013.25   ,   18.8    ,  390.9696 ,    7.     ,   24.97923,\n",
       "         121.53986],\n",
       "       [2013.     ,    8.1    ,  104.8101 ,    5.     ,   24.96674,\n",
       "         121.54067],\n",
       "       [2013.5    ,    6.5    ,   90.45606,    9.     ,   24.97433,\n",
       "         121.5431 ]], shape=(414, 6))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6bebcd-4855-4eed-a7a3-42fbe1290554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the target values y\n",
    "y = np.array(real_estate.iloc[:,6].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dee5564-2659-44b3-b432-cdfbc7ecd05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cde32b0-a298-4381-952a-ffe4f3a859f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.53, 2.81, 3.15, 3.65, 2.87, 2.14, 2.69, 3.11, 1.25, 1.47, 2.76,\n",
       "       3.87, 2.62, 1.59, 2.29, 3.37, 4.67, 2.49, 2.82, 3.18, 1.95, 3.44,\n",
       "       1.64, 3.19, 2.59, 1.8 , 3.75, 2.24, 3.13, 3.81, 1.47, 1.67, 2.28,\n",
       "       3.29, 3.67, 1.82, 1.53, 1.69, 3.18, 3.08, 1.06, 1.21, 2.31, 2.27,\n",
       "       3.59, 2.55, 2.8 , 4.1 , 0.89, 0.88, 2.95, 1.38, 1.8 , 2.59, 3.45,\n",
       "       0.91, 2.79, 3.57, 1.51, 2.83, 1.42, 4.21, 1.85, 3.67, 1.69, 2.95,\n",
       "       3.38, 3.79, 2.41, 2.8 , 3.93, 2.72, 2.42, 1.33, 3.63, 1.97, 2.45,\n",
       "       1.71, 1.99, 1.77, 2.69, 2.45, 3.21, 1.18, 2.91, 3.39, 1.8 , 1.22,\n",
       "       3.2 , 1.69, 3.03, 2.88, 1.45, 1.07, 2.73, 3.45, 3.97, 2.31, 3.4 ,\n",
       "       4.15, 2.55, 2.19, 3.63, 3.05, 2.03, 4.73, 3.14, 1.77, 2.27, 1.89,\n",
       "       3.44, 2.63, 1.54, 0.51, 3.55, 3.09, 0.81, 0.87, 2.04, 3.97, 2.09,\n",
       "       3.2 , 2.17, 3.03, 3.83, 3.24, 4.19, 3.67, 4.05, 2.73, 2.5 , 2.05,\n",
       "       2.5 , 2.63, 2.81, 1.39, 3.12, 3.16, 2.9 , 2.83, 3.43, 1.93, 2.5 ,\n",
       "       2.67, 1.89, 3.03, 3.48, 2.88, 3.01, 2.65, 3.23, 2.98, 1.93, 2.73,\n",
       "       1.38, 1.04, 1.22, 2.37, 2.63, 2.49, 3.85, 2.64, 0.77, 3.7 , 3.68,\n",
       "       2.04, 4.91, 2.89, 2.49, 1.57, 0.96, 3.92, 3.87, 2.34, 3.01, 2.43,\n",
       "       1.28, 2.8 , 2.45, 2.84, 1.03, 3.73, 1.57, 1.25, 1.45, 1.43, 1.71,\n",
       "       1.47, 2.95, 1.37, 2.82, 2.52, 2.85, 3.29, 1.95, 2.31, 2.44, 3.21,\n",
       "       2.61, 2.11, 1.7 , 3.06, 2.1 , 3.07, 1.77, 1.43, 2.93, 2.28, 1.75,\n",
       "       2.73, 3.48, 2.9 , 2.07, 3.87, 1.39, 3.21, 2.65, 2.72, 2.92, 2.68,\n",
       "       5.22, 2.57, 3.23, 2.82, 3.07, 3.27, 0.85, 2.68, 3.11, 1.27, 2.23,\n",
       "       0.98, 1.16, 2.16, 1.59, 2.62, 4.13, 2.6 , 2.71, 1.98, 1.92, 2.76,\n",
       "       2.23, 3.21, 1.45, 2.72, 2.71, 1.54, 1.49, 1.  , 2.  , 0.92, 3.51,\n",
       "       1.73, 3.45, 1.16, 1.77, 2.93, 4.22, 1.92, 2.05, 1.63, 3.53, 2.11,\n",
       "       2.71, 2.54, 1.58, 2.74, 2.67, 1.53, 7.83, 1.77, 2.7 , 1.95, 2.73,\n",
       "       3.31, 2.27, 1.85, 2.93, 2.07, 3.03, 2.99, 1.71, 1.57, 2.29, 3.69,\n",
       "       3.75, 2.19, 3.4 , 2.97, 2.47, 3.63, 1.63, 2.83, 2.54, 1.45, 2.27,\n",
       "       1.9 , 1.11, 3.07, 2.46, 2.38, 1.55, 2.56, 1.96, 3.67, 3.35, 1.65,\n",
       "       3.53, 1.27, 1.65, 2.81, 5.2 , 2.85, 2.77, 1.82, 2.8 , 2.5 , 3.32,\n",
       "       1.79, 1.24, 2.51, 2.21, 2.83, 2.09, 2.54, 4.14, 2.45, 1.57, 1.28,\n",
       "       0.85, 1.04, 2.64, 2.56, 1.52, 2.43, 2.37, 2.06, 2.42, 3.36, 2.86,\n",
       "       2.47, 3.57, 3.11, 2.75, 2.53, 2.05, 0.75, 3.58, 3.13, 2.82, 1.91,\n",
       "       1.71, 2.09, 2.01, 4.05, 3.02, 2.99, 3.01, 1.65, 3.14, 4.22, 2.67,\n",
       "       3.2 , 2.21, 1.97, 1.65, 1.39, 2.87, 1.52, 2.81, 3.45, 2.77, 3.48,\n",
       "       3.3 , 1.59, 2.03, 3.79, 2.49, 4.65, 3.55, 3.15, 1.95, 2.69, 0.86,\n",
       "       3.11, 3.69, 1.71, 1.82, 4.51, 2.57, 2.09, 2.35, 2.69, 1.65, 2.83,\n",
       "       2.13, 2.15, 1.53, 2.49, 2.37, 1.85, 1.9 , 2.65, 2.75, 2.48, 2.7 ,\n",
       "       1.49, 1.87, 1.03, 3.33, 2.71, 3.5 , 4.26])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093351ed",
   "metadata": {},
   "source": [
    "### Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cedf9e-4a41-463c-9bf6-865bc0f6f7ce",
   "metadata": {},
   "source": [
    "We can transform the continuous target variable (house price) into a categorical variable (house price range) according to the following rule.\n",
    "|price range|category|label|\n",
    "|:--:|:--:|:--:|\n",
    "|$y\\leq 1.5$|very low|0|\n",
    "|$1.5<y\\leq2.5$|low|1|\n",
    "|$2.5<y\\leq3.5$|high|2|\n",
    "|$y>3.5$|very high|3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e8e2af4-4211-42b6-8c59-c21239caca10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 3, 2, 1, 2, 2, 0, 0, 2, 3, 2, 1, 1, 2, 3, 1, 2, 2, 1, 2,\n",
       "       1, 2, 2, 1, 3, 1, 2, 3, 0, 1, 1, 2, 3, 1, 1, 1, 2, 2, 0, 0, 1, 1,\n",
       "       3, 2, 2, 3, 0, 0, 2, 0, 1, 2, 2, 0, 2, 3, 1, 2, 0, 3, 1, 3, 1, 2,\n",
       "       2, 3, 1, 2, 3, 2, 1, 0, 3, 1, 1, 1, 1, 1, 2, 1, 2, 0, 2, 2, 1, 0,\n",
       "       2, 1, 2, 2, 0, 0, 2, 2, 3, 1, 2, 3, 2, 1, 3, 2, 1, 3, 2, 1, 1, 1,\n",
       "       2, 2, 1, 0, 3, 2, 0, 0, 1, 3, 1, 2, 1, 2, 3, 2, 3, 3, 3, 2, 1, 1,\n",
       "       1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "       0, 0, 0, 1, 2, 1, 3, 2, 0, 3, 3, 1, 3, 2, 1, 1, 0, 3, 3, 1, 2, 1,\n",
       "       0, 2, 1, 2, 0, 3, 1, 0, 0, 0, 1, 0, 2, 0, 2, 2, 2, 2, 1, 1, 1, 2,\n",
       "       2, 1, 1, 2, 1, 2, 1, 0, 2, 1, 1, 2, 2, 2, 1, 3, 0, 2, 2, 2, 2, 2,\n",
       "       3, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2, 3, 2, 2, 1, 1, 2,\n",
       "       1, 2, 0, 2, 2, 1, 0, 0, 1, 0, 3, 1, 2, 0, 1, 2, 3, 1, 1, 1, 3, 1,\n",
       "       2, 2, 1, 2, 2, 1, 3, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 3,\n",
       "       3, 1, 2, 2, 1, 3, 1, 2, 2, 0, 1, 1, 0, 2, 1, 1, 1, 2, 1, 3, 2, 1,\n",
       "       3, 0, 1, 2, 3, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 2, 1, 2, 3, 1, 1, 0,\n",
       "       0, 0, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 3, 2, 2, 2, 1, 0, 3, 2, 2, 1,\n",
       "       1, 1, 1, 3, 2, 2, 2, 1, 2, 3, 2, 2, 1, 1, 1, 0, 2, 1, 2, 2, 2, 2,\n",
       "       2, 1, 1, 3, 1, 3, 3, 2, 1, 2, 0, 2, 3, 1, 1, 3, 2, 1, 1, 2, 1, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 0, 1, 0, 2, 2, 2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ = np.zeros(row_num, dtype=\"int\")\n",
    "y_[y<=1.5] = 0\n",
    "y_[(y>1.5)*(y<=2.5)] = 1\n",
    "y_[(y>2.5)*(y<=3.5)] = 2\n",
    "y_[y>3.5] = 3\n",
    "y_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f7092",
   "metadata": {},
   "source": [
    "We record the number of classes as four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fab6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1788c914-fbff-486e-8aab-e8ef995cc765",
   "metadata": {},
   "source": [
    "We transform the house features into categorical values, making it suitable for the Categorical-valued Decision Tree Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fcea0ad-a126-41d6-b4c4-25e21372996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.zeros((row_num,col_num-1),dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590af94f-47bc-4886-90b5-eb6587bdec25",
   "metadata": {},
   "source": [
    "Feature \"X1 transaction date\" is devided into two categories according to the following rule.\n",
    "|transaction date range|category|value|\n",
    "|:--:|:--:|:--:|\n",
    "|$\\text{X1}< 2013$|before 2013|0|\n",
    "|$\\text{X1}\\geq 2013$|after 2013|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdbeccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_ = np.zeros(row_num, dtype=\"int\")\n",
    "X1 = X[:,0]\n",
    "X1_[X1<2013] = 0\n",
    "X1_[X1>=2013] = 1\n",
    "X_[:,0] = X1_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71656c5d-0d5b-41e3-8755-4223ba6fccf1",
   "metadata": {},
   "source": [
    "Feature \"X2 house age\" is devided into three categories according to the following rule.\n",
    "|house age range|category|value|\n",
    "|:--:|:--:|:--:|\n",
    "|$\\text{X2}\\leq 10$|young|0|\n",
    "|$10<\\text{X2}\\leq 20$|medium|1|\n",
    "|$\\text{X2}>20$|old|2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c7cdcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_ = np.zeros(row_num, dtype=\"int\")\n",
    "X2 = X[:,1]\n",
    "X2_[X2<=10] = 0\n",
    "X2_[(X2>10)*(X2<=20)] = 1\n",
    "X2_[X2>20] = 2\n",
    "X_[:,1] = X2_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e1e92-0322-461e-aaf2-3d6509a1a6fc",
   "metadata": {},
   "source": [
    "Feature \"X3 distance to the nearest metro station\" is devided into three categories according to the following rule.\n",
    "|distance range|category|value|\n",
    "|:--:|:--:|:--:|\n",
    "|$\\text{X3}\\leq 200$|near|0|\n",
    "|$200<\\text{X3}\\leq 1000$|medium|1|\n",
    "|$\\text{X3}>1000$|far|2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20276837-220d-401c-8c72-688e233ce38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_ = np.zeros(row_num, dtype=\"int\")\n",
    "X3 = X[:,2]\n",
    "X3_[X3<=200] = 0\n",
    "X3_[(X3>200)*(X3<=1000)] = 1\n",
    "X3_[X3>1000] = 2\n",
    "X_[:,2] = X3_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190ac46-b5e0-48b2-b52b-7655452a63e3",
   "metadata": {},
   "source": [
    "Feature \"X4 number of convenience stores\" is devided into three categories according to the following rule.\n",
    "|number range|category|value|\n",
    "|:--:|:--:|:--:|\n",
    "|$\\text{X4}\\leq 3$|few|0|\n",
    "|$3<\\text{X4}\\leq 6$|medium|1|\n",
    "|$\\text{X4}>6$|many|2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00b6f296-1fe0-4307-8aa7-4867036cf164",
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_ = np.zeros(row_num, dtype=\"int\")\n",
    "X4 = X[:,3]\n",
    "X4_[X4<=3] = 0\n",
    "X4_[(X4>3)*(X4<=6)] = 1\n",
    "X4_[X4>6] = 2\n",
    "X_[:,3] = X4_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e612e3-3f8d-4316-9ff6-097a28d7d362",
   "metadata": {},
   "source": [
    "Feature \"X5 latitude\" is devided into two categories according to the following rule.\n",
    "|latitude range|category|value|\n",
    "|:--:|:--:|:--:|\n",
    "|$\\text{X5}\\leq 24.969$|north|0|\n",
    "|$\\text{X5}> 24.969$|south|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e00c6043-18b9-4c95-b4ee-47742c38d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X5_ = np.zeros(row_num, dtype=\"int\")\n",
    "X5 = X[:,4]\n",
    "X5_[X5<=24.969] = 0\n",
    "X5_[X5>24.969] = 1\n",
    "X_[:,4] = X5_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c2a30",
   "metadata": {},
   "source": [
    "Feature \"X6 longitude\" is devided into two categories according to the following rule.\n",
    "|longitude range|category|value|\n",
    "|:--:|:--:|:--:|\n",
    "|$\\text{X6}\\leq 121.535$|east|0|\n",
    "|$\\text{X6}> 121.535$|west|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cab4740a-0c99-4950-8c19-c445b5b83e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X6_ = np.zeros(row_num, dtype=\"int\")\n",
    "X6 = X[:,5]\n",
    "X6_[X6<=121.535] = 0\n",
    "X6_[X6>121.535] = 1\n",
    "X_[:,5] = X6_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e435d8",
   "metadata": {},
   "source": [
    "We record the number of categorical feature values for each transformed feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "734a28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_val_nums = [2,3,3,3,2,2] # Feature X1 has two categorical values, Feature X2 has three categorical values, ..., Feature X6 has two categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64911c3f-59c9-4d23-8965-07c9da854544",
   "metadata": {},
   "source": [
    "### Step 3: Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5367f4-fc4f-4b82-a53b-876f24153cea",
   "metadata": {},
   "source": [
    "We randomly split the data X_ and y_ into training and test sets with the ratio $1:1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44bf35ef-87e8-466f-b40d-943759fdeaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_, y_, test_size=0.5, random_state=0)\n",
    "train_num = y_train.shape[0]\n",
    "test_num = y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e879d-8774-4afc-ad1b-7a651233c01c",
   "metadata": {},
   "source": [
    "### Step 4: House Price Range Classification with ID3 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19211ac-44c4-44fb-836c-74f0c5370bf5",
   "metadata": {},
   "source": [
    "As Sciket-Learn only implements the CART decision tree with the only support for binary splits and continuous attribute values, we have to implement the ID3 Decision Tree Classifier by ourselves. Following the Decision Tree algortihm discription on page 9 of this week's lecture notes, we can implement the ID3 Decision Tree Classifier (which adopts Information Gain as the attribute selection measure) as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "787118a0-9184-4129-bc7c-a6313fcf55d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the ID3 Decision Tree Classifier, train an ID3 Decision Tree Classifier with the training data (X_train, y_train)\n",
    "\n",
    "# Compute the information (entropy) of a data collection\n",
    "def compute_information(dataset):\n",
    "    sample_num = dataset.shape[0]\n",
    "    feat_num = dataset.shape[1] - 1\n",
    "    label_counts = {}\n",
    "    for i in range(sample_num):\n",
    "        current_label = dataset[i,feat_num]\n",
    "        if current_label not in label_counts.keys():\n",
    "            label_counts[current_label] = 0\n",
    "        label_counts[current_label] += 1\n",
    "    info = 0.0\n",
    "    for label in label_counts:\n",
    "        p = label_counts[label] / sample_num\n",
    "        info -= p * np.log2(p)\n",
    "    return info\n",
    "\n",
    "# Create a subset of a given data collection, according to the given value of the given attribute  \n",
    "def create_sub_dataset(dataset, attribute_index, value):\n",
    "    attribute_values = dataset[:,attribute_index]\n",
    "    return dataset[attribute_values==value,:]\n",
    "\n",
    "# Select the splitting attribute\n",
    "def select_split_attribute(dataset, attribute_list):\n",
    "    sample_num = dataset.shape[0]\n",
    "    information = compute_information(dataset)\n",
    "    best_information_gain = -1.0\n",
    "    best_attribute_index = -1\n",
    "    for attribute_index in attribute_list:\n",
    "        information_gain = information\n",
    "        for j in range(feat_val_nums[attribute_index]):\n",
    "            sub_dataset = create_sub_dataset(dataset, attribute_index, j)\n",
    "            sub_dataset_sample_num = sub_dataset.shape[0]\n",
    "            if sub_dataset_sample_num == 0:\n",
    "                continue\n",
    "            information_gain -= sub_dataset_sample_num / sample_num * compute_information(sub_dataset)\n",
    "        if best_information_gain < information_gain:\n",
    "            best_information_gain = information_gain\n",
    "            best_attribute_index = attribute_index\n",
    "    return best_attribute_index\n",
    "\n",
    "# Use majority voting to determine the class label of a data collection\n",
    "def majority_vote(dataset):\n",
    "    sample_num = dataset.shape[0]\n",
    "    feat_num = dataset.shape[1] - 1\n",
    "    label_counts = {}\n",
    "    for i in range(sample_num):\n",
    "        current_label = dataset[i,feat_num]\n",
    "        if current_label not in label_counts.keys():\n",
    "            label_counts[current_label] = 0\n",
    "        label_counts[current_label] += 1\n",
    "\n",
    "    max_label_counts = 0\n",
    "    majority_label = -1\n",
    "    for label in label_counts:\n",
    "        if max_label_counts < label_counts[label]:\n",
    "            max_label_counts = label_counts[label]\n",
    "            majority_label = label\n",
    "    return majority_label\n",
    "\n",
    "# Check if the given data collection is pure or not\n",
    "def pure_check(dataset):\n",
    "    sample_num = dataset.shape[0]\n",
    "    feat_num = dataset.shape[1] - 1\n",
    "    label_counts = {}\n",
    "    for i in range(sample_num):\n",
    "        current_label = dataset[i,feat_num]\n",
    "        if current_label not in label_counts.keys():\n",
    "            label_counts[current_label] = 0\n",
    "        label_counts[current_label] += 1\n",
    "    if len(list(label_counts.keys())) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Create a decision tree from the given data collection and attribute list\n",
    "def create_decision_tree(dataset, attribute_list):\n",
    "    majority_label = majority_vote(dataset)\n",
    "\n",
    "    # If current data collection is pure, return the majority label\n",
    "    if pure_check(dataset):\n",
    "        return majority_label\n",
    "    \n",
    "    # If there are no attributes available to do data splitting (corresponding to the leaf node), return the majority label\n",
    "    if len(attribute_list) == 0:\n",
    "        return majority_label \n",
    "    \n",
    "    split_attribute_index = select_split_attribute(dataset, attribute_list)\n",
    "    attribute_list.remove(split_attribute_index)\n",
    "\n",
    "    decision_tree = {split_attribute_index: {}}\n",
    "    for attribute_value in range(feat_val_nums[split_attribute_index]):\n",
    "        sub_dataset = create_sub_dataset(dataset, split_attribute_index, attribute_value)\n",
    "        if sub_dataset.shape[0] == 0:\n",
    "            decision_tree[split_attribute_index][attribute_value] = majority_label\n",
    "        else:\n",
    "            decision_tree[split_attribute_index][attribute_value] = create_decision_tree(sub_dataset, attribute_list)\n",
    "    \n",
    "    return decision_tree\n",
    "\n",
    "# Given the feature vector of a test sample, predict its label using the trained decision tree\n",
    "def classify(decision_tree, test_sample):\n",
    "    root_attribute_index = list(decision_tree.keys())[0]\n",
    "    sub_decision_tree = decision_tree[root_attribute_index][test_sample[root_attribute_index]]\n",
    "    if type(sub_decision_tree).__name__ == 'dict':\n",
    "        return classify(sub_decision_tree, test_sample)\n",
    "    else:\n",
    "        return sub_decision_tree\n",
    "    \n",
    "# Train an ID3 Decision Tree Classifier with X_train, y_train\n",
    "dataset = np.zeros((train_num,col_num),dtype=int)\n",
    "dataset[:,:col_num-1] = X_train\n",
    "dataset[:,col_num-1] = y_train\n",
    "attribute_list = list(range(col_num-1))\n",
    "decision_tree = create_decision_tree(dataset, attribute_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be84f0b5-1331-4640-86e2-21cbd6ee8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of test data with the trained ID3 Decision Tree Classifier\n",
    "y_pred = np.zeros_like(y_test, dtype=int)\n",
    "for i in range(test_num):\n",
    "    y_pred[i] = classify(decision_tree, X_test[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ae86a17-7950-4b59-9de8-f06ccc914675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_pred\n",
       "0         2       2\n",
       "1         0       1\n",
       "2         2       2\n",
       "3         0       1\n",
       "4         2       1\n",
       "..      ...     ...\n",
       "202       1       2\n",
       "203       1       1\n",
       "204       1       2\n",
       "205       2       2\n",
       "206       1       1\n",
       "\n",
       "[207 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the ground-truth and predicted labels\n",
    "pd.DataFrame({'y_test': y_test, 'y_pred': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65b09d31-bab5-4983-a399-3f2ae29d4ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5748792270531401"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the accuracy score as an evaluation of the trained ID3 Decision Tree Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250fd949",
   "metadata": {},
   "source": [
    "**Task 1**: Based on the implemented ID3 Decision Tree Classifier, implement the C4.5 Decision Tree Classifier, where Information Gain is replaced by Gain Ratio to select the splitting attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f366bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the C4.5 Decision Tree Classifier, train a C4.5 Decision Tree Classifier with the training data (X_train, y_train)\n",
    "# Re-implement the splitting attribute selection function\n",
    "\n",
    "def compute_split_info(dataset, attribute_index):\n",
    "    sample_num = dataset.shape[0]\n",
    "    split_info = 0.0\n",
    "    for j in range(feat_val_nums[attribute_index]):\n",
    "        sub_dataset = create_sub_dataset(dataset, attribute_index, j)\n",
    "        sub_dataset_sample_num = sub_dataset.shape[0]\n",
    "        if sub_dataset_sample_num == 0:\n",
    "            continue\n",
    "        p = sub_dataset_sample_num / sample_num\n",
    "        split_info -= p * np.log2(p)\n",
    "    return split_info\n",
    "\n",
    "def select_split_attribute_gain_ratio(dataset, attribute_list):\n",
    "    sample_num = dataset.shape[0]\n",
    "    information = compute_information(dataset)\n",
    "    best_gain_ratio = -1.0\n",
    "    best_attribute_index = -1\n",
    "    for attribute_index in attribute_list:\n",
    "        info_gain = information\n",
    "        for j in range(feat_val_nums[attribute_index]):\n",
    "            sub_dataset = create_sub_dataset(dataset, attribute_index, j)\n",
    "            sub_sample_num = sub_dataset.shape[0]\n",
    "            if sub_sample_num == 0:\n",
    "                continue\n",
    "            info_gain -= sub_sample_num / sample_num * compute_information(sub_dataset)\n",
    "        \n",
    "        split_info = compute_split_info(dataset, attribute_index)\n",
    "\n",
    "        if split_info == 0:\n",
    "            continue\n",
    "        gain_ratio = info_gain / split_info\n",
    "\n",
    "        if gain_ratio > best_gain_ratio:\n",
    "            best_gain_ratio = gain_ratio\n",
    "            best_attribute_index = attribute_index\n",
    "    return best_attribute_index\n",
    "\n",
    "\n",
    "# Re-implement the decision tree creation function\n",
    "def create_decision_tree_gain_ratio(dataset, attribute_list):\n",
    "    majority_label = majority_vote(dataset)\n",
    "\n",
    "    if pure_check(dataset):\n",
    "        return majority_label\n",
    "\n",
    "    if len(attribute_list) == 0:\n",
    "        return majority_label \n",
    "\n",
    "    split_attribute_index = select_split_attribute_gain_ratio(dataset, attribute_list)\n",
    "    \n",
    "    if split_attribute_index == -1:\n",
    "        return majority_label\n",
    "\n",
    "    attribute_list = attribute_list.copy()\n",
    "    attribute_list.remove(split_attribute_index)\n",
    "\n",
    "    decision_tree = {split_attribute_index: {}}\n",
    "    for attribute_value in range(feat_val_nums[split_attribute_index]):\n",
    "        sub_dataset = create_sub_dataset(dataset, split_attribute_index, attribute_value)\n",
    "        if sub_dataset.shape[0] == 0:\n",
    "            decision_tree[split_attribute_index][attribute_value] = majority_label\n",
    "        else:\n",
    "            decision_tree[split_attribute_index][attribute_value] = create_decision_tree_gain_ratio(sub_dataset, attribute_list)\n",
    "    \n",
    "    return decision_tree\n",
    "\n",
    "\n",
    "\n",
    "# Train a C4.5 Decision Tree Classifier with X_train, y_train\n",
    "##: Write your code here\n",
    "dataset = np.zeros((train_num, col_num), dtype=int)\n",
    "dataset[:, :col_num-1] = X_train\n",
    "dataset[:, col_num-1] = y_train\n",
    "attribute_list = list(range(col_num - 1))\n",
    "\n",
    "decision_tree_c45 = create_decision_tree_gain_ratio(dataset, attribute_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f32fd552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of test data with the trained C4.5 Decision Tree Classifier\n",
    "y_pred = np.zeros_like(y_test, dtype=int)\n",
    "for i in range(test_num):\n",
    "    y_pred[i] = classify(decision_tree_c45, X_test[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49d8ab60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_pred\n",
       "0         2       1\n",
       "1         0       0\n",
       "2         2       2\n",
       "3         0       0\n",
       "4         2       1\n",
       "..      ...     ...\n",
       "202       1       2\n",
       "203       1       1\n",
       "204       1       2\n",
       "205       2       2\n",
       "206       1       1\n",
       "\n",
       "[207 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the ground-truth and predicted labels\n",
    "pd.DataFrame({'y_test': y_test, 'y_pred': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11f715c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6376811594202898"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the accuracy score as an evaluation of the trained C4.5 Decision Tree Classifier\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747bc53",
   "metadata": {},
   "source": [
    "**Futher Exploration (Optional)**:\n",
    "+ Based on the implemented ID3 and C4.5 Decision Tree Classifiers, implement a Decision Tree Regression model, where the reudction in mean sqaured error is used as a measure to select the splitting attribute.  Use the implement Decision Tree Regresion model to predict the house price of test samples. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
